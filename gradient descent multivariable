import numpy as np

# Generate sample data with 4 features
np.random.seed(0)
m = 100  # Number of data points
n = 4  # Number of features

# Generate random feature values and a target variable
X = 2 * np.random.rand(m, n)
y = 4 + np.dot(X, np.array([3, 2, 1, 4])) + np.random.randn(m)

# Define the cost function
def compute_cost(X, y, theta):
    m = len(y)
    predictions = X.dot(theta)
    cost = (1 / (2 * m)) * np.sum((predictions - y)**2)
    return cost

# Implement gradient descent
def gradient_descent(X, y, theta, learning_rate, num_iterations):
    m = len(y)
    cost_history = []

    for i in range(num_iterations):
        error = X.dot(theta) - y
        gradient = (1 / m) * X.T.dot(error)
        theta -= learning_rate * gradient
        cost = compute_cost(X, y, theta)
        cost_history.append(cost)

    return theta, cost_history

# Add a bias term to the input features
X_b = np.c_[np.ones((m, 1)), X]

# Initialize model parameters
initial_theta = np.random.rand(n + 1)

# Hyperparameters
learning_rate = 0.01
num_iterations = 1000

# Run gradient descent to fit the model
theta, cost_history = gradient_descent(X_b, y, initial_theta, learning_rate, num_iterations)

# Print the learned coefficients
print("Learned Coefficients:", theta)

# Evaluate the model's performance
from sklearn.metrics import mean_squared_error
y_pred = X_b.dot(theta)
mse = mean_squared_error(y, y_pred)
print("Mean Squared Error:", mse)
